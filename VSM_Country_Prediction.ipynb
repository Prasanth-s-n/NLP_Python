{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "#install if you dont have already\n",
    "#!pip install gensim\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(embeddings,words):\n",
    "    X = np.zeros((1, 300))\n",
    "    for word in words:\n",
    "        english = word\n",
    "        eng_emb = embeddings[english]\n",
    "        X = np.row_stack((X, eng_emb))\n",
    "    X = X[1:,:]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embeddings(embeddings,set_words,complete=False):\n",
    "\n",
    "    word_embeddings = {}\n",
    "    for word in embeddings.vocab:\n",
    "        if word in set_words:\n",
    "            word_embeddings[word] = embeddings[word]\n",
    "        if complete:\n",
    "            word_embeddings[word] = embeddings[word]\n",
    "    return word_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(W1,W2):\n",
    "    num = np.dot(W1,W2)\n",
    "    det = np.linalg.norm(W1)*np.linalg.norm(W2)\n",
    "    return (num/det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(W1,W2):\n",
    "    return np.linalg.norm(np.subtract(W1,W2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use this to find 4th word related to 3rd word similar to how 1 and 2 related.\n",
    "#for now since my subset mostly hav countries and cities, i have named this function as predict country\n",
    "def predict_country(city1, country1, city2, embeddings):\n",
    "    \n",
    "    group = set((city1, country1, city2))\n",
    "\n",
    "    city1_emb = embeddings[city1]\n",
    "    country1_emb = embeddings[country1]\n",
    "    city2_emb = embeddings[city2]\n",
    "    \n",
    "    vec = city2_emb-city1_emb+country1_emb\n",
    "\n",
    "    # Initialize the similarity to -1 (it will be replaced by a similarities that are closer to +1)\n",
    "    similarity = -1\n",
    "    \n",
    "    # initialize country to an empty string\n",
    "    country = ''\n",
    "    \n",
    "    # loop through all words in the embeddings dictionary\n",
    "    for word in embeddings.keys():\n",
    "        if word not in group:\n",
    "\n",
    "            word_emb = embeddings[word]\n",
    "            cur_similarity = cos_similarity(vec,word_emb) #current similarity\n",
    "            #checking whether the similarity is greater than previous similarity\n",
    "            if cur_similarity > similarity:\n",
    "                similarity = cur_similarity\n",
    "                country = word\n",
    "    return country,similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install if you dont have already\n",
    "#!pip install gensim\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will take around 2-3mins\n",
    "embeddings = KeyedVectors.load_word2vec_format('D:/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('D:/capitals.txt', 'r').read()\n",
    "set_words = set(nltk.word_tokenize(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings=get_word_embeddings(embeddings,set_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country is India with cosine similarity being 0.5113393664360046\n",
      "City is London with cosine similarity being 0.6056334972381592\n"
     ]
    }
   ],
   "source": [
    "city1='Moscow'\n",
    "country1='Russia'\n",
    "city2='NewDelhi'\n",
    "country2,similarity=predict_country(city1,country1,city2,word_embeddings)\n",
    "print(\"Country is {} with cosine similarity being {}\".format(country2,similarity))\n",
    "#Predicting City with country\n",
    "country3='England'\n",
    "city3,similarity = predict_country(country1,city1,country3,word_embeddings)\n",
    "print(\"City is {} with cosine similarity being {}\".format(city3,similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(word_embeddings, data):\n",
    "    \n",
    "    num_correct = 0\n",
    "    for i, row in data.iterrows():\n",
    "        city1 = row[0]\n",
    "        country1 = row[1]\n",
    "        city2 =  row[2]\n",
    "        country2 = row[3]\n",
    "        predicted_country2, _ = predict_country(city1,country1,city2,word_embeddings)\n",
    "\n",
    "        if predicted_country2 == country2:\n",
    "            num_correct += 1\n",
    "\n",
    "    m = len(data)\n",
    "    accuracy = num_correct/m\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D://capitals.txt', delimiter=' ')\n",
    "data.columns = ['city1', 'country1', 'city2', 'country2']\n",
    "acc=get_accuracy(word_embeddings,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.92\n"
     ]
    }
   ],
   "source": [
    "#print({acc:.2f})\n",
    "print(\"Accuracy is {:.2f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
